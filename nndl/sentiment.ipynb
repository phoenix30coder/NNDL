{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eB9btaOhiw10"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Sample data\n",
        "data = pd.DataFrame({\n",
        "    'text': ['I love this product', 'This is terrible', 'Amazing experience', 'I am not happy', 'Fantastic service'],\n",
        "    'sentiment': [1, 0, 1, 0, 1]  # 1 for positive, 0 for negative\n",
        "})\n",
        "\n",
        "# Splitting the data\n",
        "X = data['text']\n",
        "y = data['sentiment']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenization\n",
        "tokenizer = Tokenizer(num_words=5000)  # Set num_words to the size of your vocabulary\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train_sequences = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_sequences = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "# Padding sequences\n",
        "max_len = 100  # You can adjust this based on your data\n",
        "X_train_padded = pad_sequences(X_train_sequences, maxlen=max_len)\n",
        "X_test_padded = pad_sequences(X_test_sequences, maxlen=max_len)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "\n",
        "# Model parameters\n",
        "embedding_dim = 100\n",
        "rnn_units = 64\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=5000, output_dim=embedding_dim, input_length=max_len),\n",
        "    LSTM(rnn_units, return_sequences=False),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')  # Binary classification\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKrwcM_kix1y",
        "outputId": "7149ba5d-eda3-4b2f-8e58-3223601c0a1c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    X_train_padded, y_train,\n",
        "    epochs=5,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98jnc_wMi8L2",
        "outputId": "e1538a58-a061-4ae3-c97c-2c84c7772ea1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.0000e+00 - loss: 0.7020 - val_accuracy: 0.0000e+00 - val_loss: 0.7117\n",
            "Epoch 2/5\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 0.6676 - val_accuracy: 0.0000e+00 - val_loss: 0.7323\n",
            "Epoch 3/5\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 1.0000 - loss: 0.6497 - val_accuracy: 0.0000e+00 - val_loss: 0.7561\n",
            "Epoch 4/5\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 1.0000 - loss: 0.6055 - val_accuracy: 0.0000e+00 - val_loss: 0.7843\n",
            "Epoch 5/5\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 1.0000 - loss: 0.5663 - val_accuracy: 0.0000e+00 - val_loss: 0.8190\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_test_padded, y_test)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5HrXnQEi-O4",
        "outputId": "92f30618-92f8-4e49-890b-a15a2b6710a6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.0000e+00 - loss: 0.8967\n",
            "Test Accuracy: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_texts = [\"I feel bad about this!\", \"This is the good purchase ever.\"]\n",
        "new_sequences = tokenizer.texts_to_sequences(new_texts)\n",
        "new_padded = pad_sequences(new_sequences, maxlen=max_len)\n",
        "\n",
        "predictions = model.predict(new_padded)\n",
        "print(predictions)  # Outputs probabilities of the positive class\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfKaRFYCjAgp",
        "outputId": "1feb5129-6ccb-4a5c-8b5a-c5b5fbc57985"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "[[0.5823576 ]\n",
            " [0.59209865]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y5SzHyGzjCI4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}